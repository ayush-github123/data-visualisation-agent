from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import PromptTemplate
import os, json
from langchain_core.output_parsers import JsonOutputParser
from dotenv import load_dotenv

load_dotenv()


# Set up the LLM (Google Gemini or other models) using Langchain's ChatGoogleGenerativeAI
llm = ChatGoogleGenerativeAI(model="gemini-2.0-flash", temperature=0.7)

# Define the prompt template for the intent detection
intent_prompt = PromptTemplate.from_template(template="""
You are a data analysis assistant. Your job is to convert natural language queries into structured tasks for a data visualization tool.

User Query: {user_query}
Available Columns: {df_columns}

Your output MUST be a JSON object in the following format:
{{
  "task": "<one of: plot_distribution, summarize_data, correlation_analysis, filter_rows, group_by_aggregate>",
  "target_column": "<one valid column from above, or null>",
  "chart_type": "<one of: bar, line, pie, scatter, none>",
  "additional_params": {{
      "groupby": "<valid column or null>",
      "percentile": "<number or null>"
  }}
}}
""")


parser = JsonOutputParser()

# Initialize the LLM chain
llm_chain = intent_prompt | llm | parser

# Function to process the user query and get the intent
def get_task_plan_from_query(user_query: str, df_columns: list):
    # Execute LLM chain to get task intent
    result = llm_chain.invoke({"user_query": user_query, "df_columns": ", ".join(df_columns)})
    # print(result)

    return result

# Example usage
df_columns = ["Booking Status", "Price", "Date", "Age"]
user_query = "Generate a bar chart for the booking status"
task_plan = get_task_plan_from_query(user_query, df_columns)

print("Task Plan Generated by LLM:", task_plan)



